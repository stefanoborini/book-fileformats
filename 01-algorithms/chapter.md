

Algorithms




data structures
 linked list
 double linked list
 trees

keywords : PPM methods




Checksumming
CRC



Compression
Run Length Encoding

Run Length Encoding is one of the most simple lossless compression
algorithms, and in some sense also the most intuitive. It is very simple to implement,
and needs a very limited amount of resources. Many different encoding schemes
exist, but all of them work on the same principle: to replace repetitions of symbols
with a single symbol and a counter indicating the number of repetitions. For example


aaaaabbbccdeeeeeeeee -&gt; a5b3c2d1e9


The algorithm reduces a 20 bytes long string to a 10 bytes long string, under the
assumption that only one byte is used for the counter. Of course, Run Length
Encoding is efficient only with aggregated repeated information.  Typical
examples of this kind of data are bitmapped images containing large areas of
uniform color like fax data, and sparse files like databases.  When repeated
sequences do not occur, the algorithm leads to an increase of the data size,
instead of a reduction:


abccccdef -&gt; a1b1c4d1e1f1


A possible solution to this problem is to use an escape information to flag the
presence of the counter only when needed, so to avoid its storage when a single
occurrence of a character is present. A very clever trick is to use the
repetition of the symbol itself twice as the escape information: when the
algorithm meets the same symbol twice, what will follow is a run length counter
of the remaining repetitions of the symbol, and not a symbol. With this scheme,
the strings given above becomes


aaaaabbbccdeeeeeeeee -&gt; aa3bb1cc0dee7

abccccdef -&gt; abcc2def


Although an encoding of two bytes leads to a three bytes occupation (two values
and a count of zero), this choice is a good compromise.

PackBits

Packbits is a variation of Run Length Encoding aiming at reducing the
cost of two symbol repetitions. The idea is to classify two kind of data:
encoded with a Run Length Encoding scheme, and non-encoded data to be
interpreted verbatim. To differentiate between the two kinds, a single signed
byte $n$ is used as both a flag and a counter:

  if n is a positive between 0 and 127: use the following 1 + n symbols as they are (verbatim)
  if n is a negative number between -127 and -1: repeat the next symbol 1 - n times. (Run Length Encoding)
  if n is -128, ignore the value. This is implementation-dependent, but generally this value is never generated by the encoder


The algorithm operates by accumulating buffers of symbols, which get normally
written as verbatim. When a run of more than three bytes is found during the
scan, the encoding is performed until a non matching byte interrupts the encoding.
 
As an example, consider the following case:

aaabcdaaaabcdeffffffffff -&gt; -2a     : 1 - (-2) = 3  repetitions of "a"
                             2bcd   : 1 +   2  = 3  verbatim data "bcd"
                            -3a     : 1 - (-3) = 4  repetitions of "a"
                             3bcde  : 1 + 3    = 4  verbatim data "bcde"
                            -9f     : 1 - (-9) = 10 repetitions of "f"

leading to a reduction from 24 bytes to 15 bytes.

Arithmetic
Lempel-Ziv


Deflate
Huffman

The Huffman coding is a encoding technique for data compression. It works by
reducing the number of bits needed to represent a given symbol keeping into
account the relative probability of each symbol, so that frequently recurring
symbols are encoded with less bits. On average, the number of bits needed for
expressing the data is reduced.
The algorithm works by building an binary tree out of the symbols and the
associated probabilities.  Leaf nodes contain both symbol and probability,
internal nodes contain the sum of the probabilities of the child nodes. For
all the internal nodes, a value of 1 is assigned to a branch in one direction
(usually, by convention, the right direction) and a value of 0 is assigned to
the branch in the other direction.  The generated tree allows the definition of
a prefix-free code where the most frequent symbols are encoded with a reduced
number of bits. In the basic Huffman coding, encoder and decoder must agree on
the probability of each symbol, and thus the tree layout.  This can be done
deciding the layout once and for all (resulting in an implicit shared knowledge
of the encoder and the decoderi) or dynamically, where the encoder calculates
the probabilities of the actual data and creates the tree. For the decoder to
work of course this tree has to be made available explicitly, by transmitting
it together with the compressed data.

A variation of the Huffman coding, the Adaptive Huffman, readapts the
probabilities and changes the tree layout while encoding, in order to achieve
better adaptivity for data showing probability changes.


FIXME  Each leaf node contain

TODO
* confirm the left/right direction by checking the statement (originally found on wikipedia).
* check what is the ordering of the children nodes. who goes left, who goes right?
* check the cases where two probabilities are equal, and also the case when all the probabilities are equals.


Burrows Wheeler transformation
The Burrows Wheeler transformation is a lossless reversible
transformation used in the bzip2 compression program. It does not
reduce the data size, but rearranges data in order to achieve a higher
efficiency for subsequent compression schemes like RLE, move-to-front or
Lempel-Ziv.
The main concept behind Burrows Wheeler is to process a block of data of
size N to form a matrix NxN whose rows are the cyclic rotation of the block.
The resulting rows are then sorted, and the last column of the matrix is
extracted together with the row index where the original data appears. For
example, encoding the word "recurrence" leads to




recurrence          cerecurren  
ecurrencer          currencere
currencere          ecurrencer
urrencerec          encerecurr
rrencerecu    -&gt;    erecurrenc   -&gt;   nerrceeruc, 6
rencerecur          ncerecurre
encerecurr          recurrence  
ncerecurre          rencerecur
cerecurren          rrencerecu
erecurrenc          urrencerec

  initial             after           Burrows Wheeler
  matrix             sorting             result 




As we can see, the algorithm tends to aggregate similar characters,
leading to a better layout for compression. The effect is particularly strong
with text: in large blocks of english text, for example, is quite frequent to
have words like "the". During the encoding transformation, the cyclic rotation
split the entries so that the "he" part is at the beginning of the line, and
the "t" at the end. Occasionally, entries for "The" or "she" will also be
present, but in general the net effect of Burrows Wheeler will be to pack "t"
letters together thanks to the sort performed on the "he" part.
To perform the decoding, the matrix is recreated by an alternated add +
sort scheme:

 add    sort    add     sort    add      sort     add       sort  
                                                            
 n       c      nc      ce      nce      cer      ncer      cere
 e       c      ec      cu      ecu      cur      ecur      curr
 r       e      re      ec      rec      ecu      recu      ecur
 r       e      re      en      ren      enc      renc      ence
 c  -&gt;   e  -&gt;  ce  -&gt;  er  -&gt;  cer  -&gt;  ere  -&gt;  cere  -&gt;  erec -&gt; ...
 e       n      en      nc      enc      nce      ence      ncer
 e       r      er      re      ere      rec      erec      recu
 r       r      rr      re      rre      ren      rren      renc
 u       r      ur      rr      urr      rre      urre      rren
 c       u      cu      ur      cur      urr      curr      urre


        add            sort            add            sort
      
      ncerecurr      cerecurre      ncerecurre      cerecurren  
      ecurrence      currencer      ecurrencer      currencere
      recurrenc      ecurrence      recurrence      ecurrencer
      rencerecu      encerecur      rencerecur      encerecurr
...   cerecurre  -&gt;  erecurren  -&gt;  cerecurren  -&gt;  erecurrenc
      encerecur      ncerecurr      encerecurr      ncerecurre
      erecurren      recurrenc      erecurrenc      recurrence  -- row 6
      rrencerec      rencerecu      rrencerecu      rencerecur
      urrencere      rrencerec      urrencerec      rrencerecu
      currencer      urrencere      currencere      urrencerec


which recreates the M matrix. We can now extract the row with index
number 6, reobtaining the original data.


Move-to-Front

Move-to-Front is a reversible transformation algorithm used to increase
the compression efficiency, most notably after a Burrows Wheeler
transformation. It is quite fast and not very complex to implement.  Each
symbol in the input data is substituted with a value referring to the index of
the symbol in an array L.  This array is initialized with an ordered set of all
the symbols expected in the input. Every time a byte is processed, it is moved
from its current position to the position 0 of the array, moving the symbols in
between one step forward, so to fill the empty space left by the move.  As a
result, redundant symbols are preferentially encoded as small (eventually zero)
values, which can be compressed in a very efficient way.

 For example, let's suppose to apply the move-to-front algorithm to the
result of the Burrows-Wheeler application (see FIXME) "nerrceeruc". The symbols
array is initialized as L = ["c", "e", "n", "r", "u"]. The order is preferential, and normally is
lexicographic. The following sequence is produced

Move to front - encodingTo encodeL arrayencodednerrceerucc e n r uerrceerucn c e r u2rrceeruce n c r u22rceerucr e n c u223ceerucr e n c u2230eerucc r e n u22303eruce c r n u223032ruce c r n u2230320ucr e c n u22303202cu r e c n223032024c u r e n2230320243

The first value is the index of "n" in L, therefore we output 2. Then we move
"n" in the first position of L. The next symbol to encode is an "e", which is at index 2
in the current L array. Again, we output 2 and move the "e" symbol in the first position of L.
The final result is that frequently occurring symbols are encoded with small numbers, and long runs
of the same symbol gets encoded as long sequences of zeroes. For example, the
string "aaaabbbbaaaa" with L = ["a","b"] is encoded as "000010001000", which
can be compressed in a very efficient way. 

The decoding is equally simple and behaves similarly: the index is used
for selecting the entry in the L array, and after selection the symbol is moved
in front of the array.

Move to front - decodingencodedL arraydecoded2230320243c e n r u230320243n c e r un30320243e n c r une0320243r e n c uner320243r e n c unerr20243c r e n unerrc0243e c r n unerrce243e c r n unerrcee43r e c n unerrceer3u r e c nnerrceeruc u r e nnerrceeruc





Encoding





